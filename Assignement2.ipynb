{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOITgVdTCyAmNugDWq9kw8L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amsyarhazim/Assignment2/blob/main/Assignement2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fQJ6Smhy-fmj"
      },
      "outputs": [],
      "source": [
        "import torch, torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import numpy\n",
        "import random\n",
        "\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, models, transforms\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying Transforms to the Data\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "image_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
        "        transforms.RandomRotation(degrees=15),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.CenterCrop(size=224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize(size=256),\n",
        "        transforms.CenterCrop(size=224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "}\n"
      ],
      "metadata": {
        "id": "jIzPIZ73-q1f"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Data\n",
        "\n",
        "# Set train and valid directory paths\n",
        "\n",
        "# dataset = '/content/drive/My Drive/01. TEACHING/MACHINE_VISION/code/fruit_dataset'\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "dataset = '/content/gdrive/My Drive/fruit_dataset'\n",
        "\n",
        "train_directory = os.path.join(dataset, 'train')\n",
        "test_directory = os.path.join(dataset, 'validation')\n",
        "\n",
        "# Batch size\n",
        "batchSize = 32\n",
        "\n",
        "# Number of classes\n",
        "num_classes = len(os.listdir(train_directory))\n",
        "print(num_classes)\n",
        "\n",
        "# Load Data from folders\n",
        "data = {\n",
        "    'train': datasets.ImageFolder(root=train_directory, transform=image_transforms['train']),\n",
        "\n",
        "    'test': datasets.ImageFolder(root=test_directory, transform=image_transforms['test'])\n",
        "}\n",
        "\n",
        "# Get a mapping of the indices to the class names, in order to see the output classes of the test images.\n",
        "# idx_to_class = {v: k for k, v in data['train'].class_to_idx.items()}\n",
        "# print(idx_to_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeqUdcA6-txx",
        "outputId": "9731ffd9-b0ce-4d47-ec7f-389cca19697f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['train']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ranaeSEL-vpF",
        "outputId": "77990101-8dc0-4ab4-f283-5b3f1becef78"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset ImageFolder\n",
              "    Number of datapoints: 462\n",
              "    Root location: /content/gdrive/My Drive/fruit_dataset/train\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               RandomResizedCrop(size=(256, 256), scale=(0.8, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear)\n",
              "               RandomRotation(degrees=[-15.0, 15.0], interpolation=nearest, expand=False, fill=0)\n",
              "               RandomHorizontalFlip(p=0.5)\n",
              "               CenterCrop(size=(224, 224))\n",
              "               ToTensor()\n",
              "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Size of Data, to be used for calculating Average Loss and Accuracy\n",
        "train_data_size = len(data['train'])\n",
        "# valid_data_size = len(data['valid'])\n",
        "test_data_size = len(data['test'])\n",
        "\n",
        "# Create iterators for the Data loaded using DataLoader module\n",
        "train_data_loader = DataLoader(data['train'], batch_size=batchSize, shuffle=True)\n",
        "# valid_data_loader = DataLoader(data['valid'], batch_size=batchSize, shuffle=True)\n",
        "test_data_loader = DataLoader(data['test'], batch_size=batchSize, shuffle=True)"
      ],
      "metadata": {
        "id": "SgaQ7YH_-xKE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_size, test_data_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9zcEFks-xb-",
        "outputId": "c9e37a77-ae47-4d82-8ff0-52b1efa13ae8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(462, 323)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = (3,32,32)"
      ],
      "metadata": {
        "id": "bHndgflc-zAp"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################################\n",
        "#                  Create Dataloader                     #\n",
        "#######################################################\n",
        "\n",
        "# Turn train and test custom Dataset's into DataLoader's\n",
        "from torch.utils.data import DataLoader\n",
        "trainloader = DataLoader(dataset=data['train'], # use custom created train Dataset\n",
        "                                     batch_size=32, # how many samples per batch?\n",
        "                                     num_workers=0, # how many subprocesses to use for data loading? (higher = more)\n",
        "                                     shuffle=True) # shuffle the data?\n",
        "\n",
        "testloader = DataLoader(dataset=data['test'], # use custom created test Dataset\n",
        "                                    batch_size=4, \n",
        "                                    num_workers=0, \n",
        "                                    shuffle=False) # don't usually need to shuffle testing data\n",
        "\n",
        "train_data_size = len(trainloader.dataset)\n",
        "test_data_size = len(testloader.dataset)\n",
        "\n",
        "print(train_data_size)\n",
        "print(test_data_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoJZ5z_2-0Ql",
        "outputId": "0953d3dd-f02e-44cc-885a-5a651b46e97b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "462\n",
            "323\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#######################\n",
        "model = models.resnet18(pretrained = True)\n",
        "#######################\n",
        "\n",
        "\n",
        "# 2. LOSS AND OPTIMIZER\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# 3. move the model to GPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Z-Qjxam-1_I",
        "outputId": "8d4144b2-c4cd-4877-b26b-492e0e55aea5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time # to calculate training time\n",
        "\n",
        "def train_and_validate(model, loss_criterion, optimizer, epochs=25):\n",
        "    '''\n",
        "    Function to train and validate\n",
        "    Parameters\n",
        "        :param model: Model to train and validate\n",
        "        :param loss_criterion: Loss Criterion to minimize\n",
        "        :param optimizer: Optimizer for computing gradients\n",
        "        :param epochs: Number of epochs (default=25)\n",
        "  \n",
        "    Returns\n",
        "        model: Trained Model with best validation accuracy\n",
        "        history: (dict object): Having training loss, accuracy and validation loss, accuracy\n",
        "    '''\n",
        "    \n",
        "    start = time.time()\n",
        "    history = []\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_start = time.time()\n",
        "        print(\"Epoch: {}/{}\".format(epoch+1, epochs))\n",
        "        \n",
        "        # Set to training mode\n",
        "        model.train()\n",
        "        \n",
        "        # Loss and Accuracy within the epoch\n",
        "        train_loss = 0.0\n",
        "        train_acc = 0.0\n",
        "        \n",
        "        valid_loss = 0.0\n",
        "        valid_acc = 0.0\n",
        "        \n",
        "        for i, (inputs, labels) in enumerate(trainloader):\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            # Clean existing gradients\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # Forward pass - compute outputs on input data using the model\n",
        "            outputs = model(inputs)\n",
        "            \n",
        "            # Compute loss\n",
        "            loss = loss_criterion(outputs, labels)\n",
        "            \n",
        "            # Backpropagate the gradients\n",
        "            loss.backward()\n",
        "            \n",
        "            # Update the parameters\n",
        "            optimizer.step()\n",
        "            \n",
        "            # Compute the total loss for the batch and add it to train_loss\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "            \n",
        "            # Compute the accuracy\n",
        "            ret, predictions = torch.max(outputs.data, 1)\n",
        "            correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
        "            \n",
        "            # Convert correct_counts to float and then compute the mean\n",
        "            acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
        "            \n",
        "            # Compute total accuracy in the whole batch and add to train_acc\n",
        "            train_acc += acc.item() * inputs.size(0)\n",
        "            \n",
        "            #print(\"Batch number: {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}\".format(i, loss.item(), acc.item()))\n",
        "\n",
        "            \n",
        "        # Validation - No gradient tracking needed\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # Set to evaluation mode\n",
        "            model.eval()\n",
        "\n",
        "            # Validation loop\n",
        "            for j, (inputs, labels) in enumerate(testloader):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Forward pass - compute outputs on input data using the model\n",
        "                outputs = model(inputs)\n",
        "\n",
        "                # Compute loss\n",
        "                loss = loss_criterion(outputs, labels)\n",
        "\n",
        "                # Compute the total loss for the batch and add it to valid_loss\n",
        "                valid_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "                # Calculate validation accuracy\n",
        "                ret, predictions = torch.max(outputs.data, 1)\n",
        "                correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
        "\n",
        "                # Convert correct_counts to float and then compute the mean\n",
        "                acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
        "\n",
        "                # Compute total accuracy in the whole batch and add to valid_acc\n",
        "                valid_acc += acc.item() * inputs.size(0)\n",
        "\n",
        "                #print(\"Validation Batch number: {:03d}, Validation: Loss: {:.4f}, Accuracy: {:.4f}\".format(j, loss.item(), acc.item()))\n",
        "            \n",
        "        # Find average training loss and training accuracy\n",
        "        avg_train_loss = train_loss/train_data_size \n",
        "        avg_train_acc = train_acc/train_data_size\n",
        "\n",
        "        # Find average training loss and training accuracy\n",
        "        avg_test_loss = valid_loss/test_data_size \n",
        "        avg_test_acc = valid_acc/test_data_size\n",
        "\n",
        "        history.append([avg_train_loss, avg_test_loss, avg_train_acc, avg_test_acc])\n",
        "                \n",
        "        epoch_end = time.time()\n",
        "    \n",
        "        print(\"Epoch : {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}%, \\n\\t\\tValidation : Loss : {:.4f}, Accuracy: {:.4f}%, Time: {:.4f}s\".format(epoch, avg_train_loss, avg_train_acc*100, avg_test_loss, avg_test_acc*100, epoch_end-epoch_start))\n",
        "        \n",
        "        # Save if the model has best accuracy till now\n",
        "        torch.save(model, 'cifar10_model_'+str(epoch)+'.pt')\n",
        "            \n",
        "    return model, history"
      ],
      "metadata": {
        "id": "rRnMuKtc-3qO"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Train the model for 10 epochs\n",
        " \n",
        "num_epochs = 20\n",
        "trained_model, history = train_and_validate(model, criterion, optimizer, num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siW4c6C--6qf",
        "outputId": "65180938-1dde-4098-b95d-919b650fc3de"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/20\n",
            "Epoch : 000, Training: Loss: 5.5963, Accuracy: 27.9221%, \n",
            "\t\tValidation : Loss : 3.7703, Accuracy: 32.5077%, Time: 60.7260s\n",
            "Epoch: 2/20\n",
            "Epoch : 001, Training: Loss: 0.3016, Accuracy: 90.4762%, \n",
            "\t\tValidation : Loss : 0.4711, Accuracy: 87.6161%, Time: 5.2299s\n",
            "Epoch: 3/20\n",
            "Epoch : 002, Training: Loss: 0.0419, Accuracy: 98.4848%, \n",
            "\t\tValidation : Loss : 0.2216, Accuracy: 95.6656%, Time: 5.1588s\n",
            "Epoch: 4/20\n",
            "Epoch : 003, Training: Loss: 0.0294, Accuracy: 99.3506%, \n",
            "\t\tValidation : Loss : 0.1834, Accuracy: 96.5944%, Time: 5.2798s\n",
            "Epoch: 5/20\n",
            "Epoch : 004, Training: Loss: 0.0155, Accuracy: 99.5671%, \n",
            "\t\tValidation : Loss : 0.1835, Accuracy: 95.9752%, Time: 5.2047s\n",
            "Epoch: 6/20\n",
            "Epoch : 005, Training: Loss: 0.0230, Accuracy: 99.5671%, \n",
            "\t\tValidation : Loss : 0.1706, Accuracy: 96.2848%, Time: 5.0872s\n",
            "Epoch: 7/20\n",
            "Epoch : 006, Training: Loss: 0.0082, Accuracy: 100.0000%, \n",
            "\t\tValidation : Loss : 0.1598, Accuracy: 96.9040%, Time: 5.1245s\n",
            "Epoch: 8/20\n",
            "Epoch : 007, Training: Loss: 0.0067, Accuracy: 100.0000%, \n",
            "\t\tValidation : Loss : 0.1802, Accuracy: 96.2848%, Time: 5.0279s\n",
            "Epoch: 9/20\n",
            "Epoch : 008, Training: Loss: 0.0370, Accuracy: 98.9177%, \n",
            "\t\tValidation : Loss : 0.1754, Accuracy: 96.2848%, Time: 5.0791s\n",
            "Epoch: 10/20\n",
            "Epoch : 009, Training: Loss: 0.0130, Accuracy: 99.5671%, \n",
            "\t\tValidation : Loss : 0.1687, Accuracy: 96.2848%, Time: 5.0799s\n",
            "Epoch: 11/20\n",
            "Epoch : 010, Training: Loss: 0.0150, Accuracy: 99.7835%, \n",
            "\t\tValidation : Loss : 0.1714, Accuracy: 95.6656%, Time: 5.0623s\n",
            "Epoch: 12/20\n",
            "Epoch : 011, Training: Loss: 0.0153, Accuracy: 99.3506%, \n",
            "\t\tValidation : Loss : 0.1892, Accuracy: 95.9752%, Time: 5.0710s\n",
            "Epoch: 13/20\n",
            "Epoch : 012, Training: Loss: 0.0227, Accuracy: 99.3506%, \n",
            "\t\tValidation : Loss : 0.1749, Accuracy: 96.5944%, Time: 5.1981s\n",
            "Epoch: 14/20\n",
            "Epoch : 013, Training: Loss: 0.0309, Accuracy: 99.1342%, \n",
            "\t\tValidation : Loss : 0.1831, Accuracy: 95.6656%, Time: 5.0374s\n",
            "Epoch: 15/20\n",
            "Epoch : 014, Training: Loss: 0.0122, Accuracy: 99.5671%, \n",
            "\t\tValidation : Loss : 0.1682, Accuracy: 96.2848%, Time: 5.0824s\n",
            "Epoch: 16/20\n",
            "Epoch : 015, Training: Loss: 0.0220, Accuracy: 99.1342%, \n",
            "\t\tValidation : Loss : 0.1811, Accuracy: 95.6656%, Time: 5.1287s\n",
            "Epoch: 17/20\n",
            "Epoch : 016, Training: Loss: 0.0095, Accuracy: 99.5671%, \n",
            "\t\tValidation : Loss : 0.1651, Accuracy: 97.2136%, Time: 5.0184s\n",
            "Epoch: 18/20\n",
            "Epoch : 017, Training: Loss: 0.0138, Accuracy: 99.5671%, \n",
            "\t\tValidation : Loss : 0.1649, Accuracy: 96.5944%, Time: 5.0517s\n",
            "Epoch: 19/20\n",
            "Epoch : 018, Training: Loss: 0.0068, Accuracy: 99.7835%, \n",
            "\t\tValidation : Loss : 0.1563, Accuracy: 96.2848%, Time: 5.0816s\n",
            "Epoch: 20/20\n",
            "Epoch : 019, Training: Loss: 0.0062, Accuracy: 99.7835%, \n",
            "\t\tValidation : Loss : 0.1675, Accuracy: 96.2848%, Time: 5.0871s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Analyze the loss curve\n",
        "\n",
        "history = np.array(history)\n",
        "plt.plot(history[:,0:2])\n",
        "plt.legend(['Tr Loss', 'Val Loss'])\n",
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel('Loss')\n",
        "plt.ylim(0,3)\n",
        "# plt.savefig('cifar10_loss_curve.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "ecUhb2nw-8HF",
        "outputId": "d37b13ea-571b-42dc-fe8e-8ce5d2707324"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Analyze the accuracy curve\n",
        "\n",
        "plt.plot(history[:,2:4])\n",
        "plt.legend(['Tr Accuracy', 'Val Accuracy'])\n",
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim(0,1)\n",
        "# plt.savefig('cifar10_accuracy_curve.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "-TzkIGne-9aO",
        "outputId": "b97a19b4-8cab-4163-fc76-f6bb0e6a0f4d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import dependencies\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "import time\n",
        "\n",
        "\n",
        "# function to convert the JavaScript object into an OpenCV image\n",
        "def js_to_image(js_reply):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "  Returns:\n",
        "          img: OpenCV BGR image\n",
        "  \"\"\"\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img\n",
        "\n",
        "# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n",
        "def bbox_to_bytes(bbox_array):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n",
        "  Returns:\n",
        "        bytes: Base64 image byte string\n",
        "  \"\"\"\n",
        "  # convert array into PIL image\n",
        "  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
        "  iobuf = io.BytesIO()\n",
        "  # format bbox into png for return\n",
        "  bbox_PIL.save(iobuf, format='png')\n",
        "  # format return string\n",
        "  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "\n",
        "  return bbox_bytes"
      ],
      "metadata": {
        "id": "GFSIAclJ--2H"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# JavaScript to properly create our live video stream using our webcam as input\n",
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "    \n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "    \n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "    \n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "    \n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "      \n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "           \n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "      \n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML = \n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\n",
        "          'When finished, click here or on the video to stop this demo</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "      \n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 640; //video.videoWidth;\n",
        "      captureCanvas.height = 480; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "      \n",
        "      return stream;\n",
        "    }\n",
        "    async function stream_frame(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "      \n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "            \n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "      \n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "      \n",
        "      return {'create': preShow - preCreate, \n",
        "              'show': preCapture - preShow, \n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "  \n",
        "def video_frame(label, bbox):\n",
        "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
        "  return data"
      ],
      "metadata": {
        "id": "4PzKI6PB_B30"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "transform=transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(size=224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "    ])\n"
      ],
      "metadata": {
        "id": "oq7FUErBBSLG"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categories = ['Durian','Pumpkin','Tomato','Watermelon']"
      ],
      "metadata": {
        "id": "w6EXT4kKBVe1"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# start streaming video from webcam\n",
        "video_stream()\n",
        "# label for video\n",
        "label_html = 'Capturing...'\n",
        "# initialze bounding box to empty\n",
        "bbox = ''\n",
        "count = 0 \n",
        "while True:\n",
        "    js_reply = video_frame(label_html, bbox)\n",
        "    if not js_reply:\n",
        "        break\n",
        "\n",
        "    # convert JS response to OpenCV Image\n",
        "    frame = js_to_image(js_reply[\"img\"])\n",
        "\n",
        "    #     rgb_image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    # Apply transforms to the input image.\n",
        "    input_tensor = transform(frame)\n",
        "    # Add the batch dimension.\n",
        "    input_batch = input_tensor.unsqueeze(0)\n",
        "    input_batch = input_batch.to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        start_time = time.time()\n",
        "        output = model(input_batch)\n",
        "        end_time = time.time()\n",
        "    # Get the softmax probabilities.\n",
        "    probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
        "    # Check the top 5 categories that are predicted.\n",
        "    top5_prob, top5_catid = torch.topk(probabilities, 4)\n",
        "    \n",
        "    cv2.putText(frame, f\"{top5_prob[0].item()*100:.3f}%\", (15, (1)*30), \n",
        "                cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                1, (0, 0, 255), 2, cv2.LINE_AA)\n",
        "    cv2.putText(frame, f\"{categories[top5_catid[0]]}\", (160, (1)*30), \n",
        "                cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                1, (0, 0, 255), 2, cv2.LINE_AA)\n",
        "    print(categories[top5_catid[0]], top5_prob[0].item())\n",
        "    cv2_imshow(frame)"
      ],
      "metadata": {
        "id": "p6hOm38-_GQ6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}